{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# prerequisites\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\nfrom torchvision.utils import save_image\n\nbs = 100\n# MNIST Dataset\ntrain_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\ntest_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n\n# Data Loader (Input Pipeline)\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:40:09.611328Z","iopub.execute_input":"2023-04-19T06:40:09.611989Z","iopub.status.idle":"2023-04-19T06:40:09.698997Z","shell.execute_reply.started":"2023-04-19T06:40:09.611951Z","shell.execute_reply":"2023-04-19T06:40:09.698006Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n        super(VAE, self).__init__()\n        \n        # encoder part\n        self.fc1 = nn.Linear(x_dim, h_dim1)\n        self.fc2 = nn.Linear(h_dim1, h_dim2)\n        self.fc31 = nn.Linear(h_dim2, z_dim)\n        self.fc32 = nn.Linear(h_dim2, z_dim)\n        # decoder part\n        self.fc4 = nn.Linear(z_dim, h_dim2)\n        self.fc5 = nn.Linear(h_dim2, h_dim1)\n        self.fc6 = nn.Linear(h_dim1, x_dim)\n        \n    def encoder(self, x):\n        h = F.relu(self.fc1(x))\n        h = F.relu(self.fc2(h))\n        return self.fc31(h), self.fc32(h) # mu, log_var\n    \n    def sampling(self, mu, log_var):\n        std = torch.exp(0.5*log_var)\n        eps = torch.randn_like(std)\n        return eps.mul(std).add_(mu) # return z sample\n        \n    def decoder(self, z):\n        h = F.relu(self.fc4(z))\n        h = F.relu(self.fc5(h))\n        return F.sigmoid(self.fc6(h)) \n    \n    def forward(self, x):\n        mu, log_var = self.encoder(x.view(-1, 784))\n        z = self.sampling(mu, log_var)\n        return self.decoder(z), mu, log_var\n\n# build model\nvae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\nif torch.cuda.is_available():\n    vae.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:40:09.700922Z","iopub.execute_input":"2023-04-19T06:40:09.701404Z","iopub.status.idle":"2023-04-19T06:40:12.675337Z","shell.execute_reply.started":"2023-04-19T06:40:09.701366Z","shell.execute_reply":"2023-04-19T06:40:12.674317Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"vae","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:40:12.676677Z","iopub.execute_input":"2023-04-19T06:40:12.679027Z","iopub.status.idle":"2023-04-19T06:40:12.686912Z","shell.execute_reply.started":"2023-04-19T06:40:12.678985Z","shell.execute_reply":"2023-04-19T06:40:12.685805Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"VAE(\n  (fc1): Linear(in_features=784, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=256, bias=True)\n  (fc31): Linear(in_features=256, out_features=2, bias=True)\n  (fc32): Linear(in_features=256, out_features=2, bias=True)\n  (fc4): Linear(in_features=2, out_features=256, bias=True)\n  (fc5): Linear(in_features=256, out_features=512, bias=True)\n  (fc6): Linear(in_features=512, out_features=784, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.Adam(vae.parameters())\n# return reconstruction error + KL divergence losses\ndef loss_function(recon_x, x, mu, log_var):\n    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n    return BCE + KLD","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:40:12.689786Z","iopub.execute_input":"2023-04-19T06:40:12.690227Z","iopub.status.idle":"2023-04-19T06:40:12.697895Z","shell.execute_reply.started":"2023-04-19T06:40:12.690191Z","shell.execute_reply":"2023-04-19T06:40:12.696960Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def train(epoch):\n    vae.train()\n    train_loss = 0\n    for batch_idx, (data, _) in enumerate(train_loader):\n        data = data.cuda()\n        optimizer.zero_grad()\n        \n        recon_batch, mu, log_var = vae(data)\n        loss = loss_function(recon_batch, data, mu, log_var)\n        \n        loss.backward()\n        train_loss += loss.item()\n        optimizer.step()\n        \n        if batch_idx % 100 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:40:12.699253Z","iopub.execute_input":"2023-04-19T06:40:12.699734Z","iopub.status.idle":"2023-04-19T06:40:12.709661Z","shell.execute_reply.started":"2023-04-19T06:40:12.699699Z","shell.execute_reply":"2023-04-19T06:40:12.708693Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def test():\n    vae.eval()\n    test_loss= 0\n    with torch.no_grad():\n        for data, _ in test_loader:\n            data = data.cuda()\n            recon, mu, log_var = vae(data)\n            \n            # sum up batch loss\n            test_loss += loss_function(recon, data, mu, log_var).item()\n        \n    test_loss /= len(test_loader.dataset)\n    print('====> Test set loss: {:.4f}'.format(test_loss))","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:40:12.710916Z","iopub.execute_input":"2023-04-19T06:40:12.711638Z","iopub.status.idle":"2023-04-19T06:40:12.723801Z","shell.execute_reply.started":"2023-04-19T06:40:12.711601Z","shell.execute_reply":"2023-04-19T06:40:12.722798Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, 51):\n    train(epoch)\n    test()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-19T06:40:12.726901Z","iopub.execute_input":"2023-04-19T06:40:12.727191Z","iopub.status.idle":"2023-04-19T06:47:04.927722Z","shell.execute_reply.started":"2023-04-19T06:40:12.727165Z","shell.execute_reply":"2023-04-19T06:47:04.926458Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","output_type":"stream"},{"name":"stdout","text":"Train Epoch: 1 [0/60000 (0%)]\tLoss: 543.717617\nTrain Epoch: 1 [10000/60000 (17%)]\tLoss: 191.118125\nTrain Epoch: 1 [20000/60000 (33%)]\tLoss: 182.807480\nTrain Epoch: 1 [30000/60000 (50%)]\tLoss: 171.991602\nTrain Epoch: 1 [40000/60000 (67%)]\tLoss: 162.477910\nTrain Epoch: 1 [50000/60000 (83%)]\tLoss: 165.058809\n====> Epoch: 1 Average loss: 180.4548\n====> Test set loss: 162.7676\nTrain Epoch: 2 [0/60000 (0%)]\tLoss: 157.841445\nTrain Epoch: 2 [10000/60000 (17%)]\tLoss: 176.345469\nTrain Epoch: 2 [20000/60000 (33%)]\tLoss: 162.873730\nTrain Epoch: 2 [30000/60000 (50%)]\tLoss: 159.856104\nTrain Epoch: 2 [40000/60000 (67%)]\tLoss: 164.100332\nTrain Epoch: 2 [50000/60000 (83%)]\tLoss: 153.926504\n====> Epoch: 2 Average loss: 159.1057\n====> Test set loss: 155.6046\nTrain Epoch: 3 [0/60000 (0%)]\tLoss: 152.679463\nTrain Epoch: 3 [10000/60000 (17%)]\tLoss: 163.828633\nTrain Epoch: 3 [20000/60000 (33%)]\tLoss: 145.641182\nTrain Epoch: 3 [30000/60000 (50%)]\tLoss: 162.269346\nTrain Epoch: 3 [40000/60000 (67%)]\tLoss: 150.077207\nTrain Epoch: 3 [50000/60000 (83%)]\tLoss: 142.791387\n====> Epoch: 3 Average loss: 153.8344\n====> Test set loss: 150.9505\nTrain Epoch: 4 [0/60000 (0%)]\tLoss: 148.055283\nTrain Epoch: 4 [10000/60000 (17%)]\tLoss: 155.047734\nTrain Epoch: 4 [20000/60000 (33%)]\tLoss: 156.707744\nTrain Epoch: 4 [30000/60000 (50%)]\tLoss: 149.106270\nTrain Epoch: 4 [40000/60000 (67%)]\tLoss: 151.751475\nTrain Epoch: 4 [50000/60000 (83%)]\tLoss: 143.086289\n====> Epoch: 4 Average loss: 150.5332\n====> Test set loss: 149.3803\nTrain Epoch: 5 [0/60000 (0%)]\tLoss: 145.943926\nTrain Epoch: 5 [10000/60000 (17%)]\tLoss: 156.834531\nTrain Epoch: 5 [20000/60000 (33%)]\tLoss: 149.101240\nTrain Epoch: 5 [30000/60000 (50%)]\tLoss: 150.903779\nTrain Epoch: 5 [40000/60000 (67%)]\tLoss: 143.160215\nTrain Epoch: 5 [50000/60000 (83%)]\tLoss: 149.147422\n====> Epoch: 5 Average loss: 148.2875\n====> Test set loss: 147.5876\nTrain Epoch: 6 [0/60000 (0%)]\tLoss: 149.741875\nTrain Epoch: 6 [10000/60000 (17%)]\tLoss: 148.366699\nTrain Epoch: 6 [20000/60000 (33%)]\tLoss: 143.715889\nTrain Epoch: 6 [30000/60000 (50%)]\tLoss: 144.265225\nTrain Epoch: 6 [40000/60000 (67%)]\tLoss: 154.039912\nTrain Epoch: 6 [50000/60000 (83%)]\tLoss: 143.566914\n====> Epoch: 6 Average loss: 146.8065\n====> Test set loss: 146.2334\nTrain Epoch: 7 [0/60000 (0%)]\tLoss: 143.404805\nTrain Epoch: 7 [10000/60000 (17%)]\tLoss: 148.887910\nTrain Epoch: 7 [20000/60000 (33%)]\tLoss: 143.302783\nTrain Epoch: 7 [30000/60000 (50%)]\tLoss: 137.303848\nTrain Epoch: 7 [40000/60000 (67%)]\tLoss: 144.638809\nTrain Epoch: 7 [50000/60000 (83%)]\tLoss: 145.118018\n====> Epoch: 7 Average loss: 145.5439\n====> Test set loss: 144.8938\nTrain Epoch: 8 [0/60000 (0%)]\tLoss: 144.638535\nTrain Epoch: 8 [10000/60000 (17%)]\tLoss: 146.900605\nTrain Epoch: 8 [20000/60000 (33%)]\tLoss: 154.713828\nTrain Epoch: 8 [30000/60000 (50%)]\tLoss: 145.616973\nTrain Epoch: 8 [40000/60000 (67%)]\tLoss: 148.255986\nTrain Epoch: 8 [50000/60000 (83%)]\tLoss: 146.516670\n====> Epoch: 8 Average loss: 144.6254\n====> Test set loss: 145.0832\nTrain Epoch: 9 [0/60000 (0%)]\tLoss: 136.878564\nTrain Epoch: 9 [10000/60000 (17%)]\tLoss: 146.571035\nTrain Epoch: 9 [20000/60000 (33%)]\tLoss: 147.291680\nTrain Epoch: 9 [30000/60000 (50%)]\tLoss: 143.912305\nTrain Epoch: 9 [40000/60000 (67%)]\tLoss: 145.833184\nTrain Epoch: 9 [50000/60000 (83%)]\tLoss: 142.348945\n====> Epoch: 9 Average loss: 143.8031\n====> Test set loss: 144.0502\nTrain Epoch: 10 [0/60000 (0%)]\tLoss: 148.079844\nTrain Epoch: 10 [10000/60000 (17%)]\tLoss: 136.640254\nTrain Epoch: 10 [20000/60000 (33%)]\tLoss: 146.701221\nTrain Epoch: 10 [30000/60000 (50%)]\tLoss: 135.624297\nTrain Epoch: 10 [40000/60000 (67%)]\tLoss: 142.587617\nTrain Epoch: 10 [50000/60000 (83%)]\tLoss: 134.803965\n====> Epoch: 10 Average loss: 143.2432\n====> Test set loss: 142.9715\nTrain Epoch: 11 [0/60000 (0%)]\tLoss: 142.591973\nTrain Epoch: 11 [10000/60000 (17%)]\tLoss: 143.009580\nTrain Epoch: 11 [20000/60000 (33%)]\tLoss: 137.522109\nTrain Epoch: 11 [30000/60000 (50%)]\tLoss: 138.990498\nTrain Epoch: 11 [40000/60000 (67%)]\tLoss: 143.979854\nTrain Epoch: 11 [50000/60000 (83%)]\tLoss: 144.159717\n====> Epoch: 11 Average loss: 142.5612\n====> Test set loss: 142.6543\nTrain Epoch: 12 [0/60000 (0%)]\tLoss: 139.314092\nTrain Epoch: 12 [10000/60000 (17%)]\tLoss: 141.646943\nTrain Epoch: 12 [20000/60000 (33%)]\tLoss: 142.508389\nTrain Epoch: 12 [30000/60000 (50%)]\tLoss: 151.424307\nTrain Epoch: 12 [40000/60000 (67%)]\tLoss: 140.887832\nTrain Epoch: 12 [50000/60000 (83%)]\tLoss: 147.594561\n====> Epoch: 12 Average loss: 141.8709\n====> Test set loss: 142.4236\nTrain Epoch: 13 [0/60000 (0%)]\tLoss: 128.159424\nTrain Epoch: 13 [10000/60000 (17%)]\tLoss: 139.318545\nTrain Epoch: 13 [20000/60000 (33%)]\tLoss: 142.191328\nTrain Epoch: 13 [30000/60000 (50%)]\tLoss: 145.675088\nTrain Epoch: 13 [40000/60000 (67%)]\tLoss: 139.456699\nTrain Epoch: 13 [50000/60000 (83%)]\tLoss: 143.674668\n====> Epoch: 13 Average loss: 141.4930\n====> Test set loss: 141.5724\nTrain Epoch: 14 [0/60000 (0%)]\tLoss: 140.544355\nTrain Epoch: 14 [10000/60000 (17%)]\tLoss: 149.303477\nTrain Epoch: 14 [20000/60000 (33%)]\tLoss: 130.759443\nTrain Epoch: 14 [30000/60000 (50%)]\tLoss: 145.280615\nTrain Epoch: 14 [40000/60000 (67%)]\tLoss: 141.675615\nTrain Epoch: 14 [50000/60000 (83%)]\tLoss: 144.519795\n====> Epoch: 14 Average loss: 140.8807\n====> Test set loss: 141.5691\nTrain Epoch: 15 [0/60000 (0%)]\tLoss: 138.455225\nTrain Epoch: 15 [10000/60000 (17%)]\tLoss: 136.856250\nTrain Epoch: 15 [20000/60000 (33%)]\tLoss: 141.680254\nTrain Epoch: 15 [30000/60000 (50%)]\tLoss: 146.532363\nTrain Epoch: 15 [40000/60000 (67%)]\tLoss: 139.547666\nTrain Epoch: 15 [50000/60000 (83%)]\tLoss: 142.668945\n====> Epoch: 15 Average loss: 140.5510\n====> Test set loss: 141.3989\nTrain Epoch: 16 [0/60000 (0%)]\tLoss: 144.628965\nTrain Epoch: 16 [10000/60000 (17%)]\tLoss: 133.148369\nTrain Epoch: 16 [20000/60000 (33%)]\tLoss: 135.525508\nTrain Epoch: 16 [30000/60000 (50%)]\tLoss: 143.881504\nTrain Epoch: 16 [40000/60000 (67%)]\tLoss: 144.101172\nTrain Epoch: 16 [50000/60000 (83%)]\tLoss: 144.913174\n====> Epoch: 16 Average loss: 140.0860\n====> Test set loss: 140.5504\nTrain Epoch: 17 [0/60000 (0%)]\tLoss: 147.663818\nTrain Epoch: 17 [10000/60000 (17%)]\tLoss: 140.150342\nTrain Epoch: 17 [20000/60000 (33%)]\tLoss: 137.250713\nTrain Epoch: 17 [30000/60000 (50%)]\tLoss: 138.330693\nTrain Epoch: 17 [40000/60000 (67%)]\tLoss: 142.077979\nTrain Epoch: 17 [50000/60000 (83%)]\tLoss: 139.213213\n====> Epoch: 17 Average loss: 139.9100\n====> Test set loss: 140.3965\nTrain Epoch: 18 [0/60000 (0%)]\tLoss: 136.614805\nTrain Epoch: 18 [10000/60000 (17%)]\tLoss: 143.417900\nTrain Epoch: 18 [20000/60000 (33%)]\tLoss: 146.844297\nTrain Epoch: 18 [30000/60000 (50%)]\tLoss: 141.321895\nTrain Epoch: 18 [40000/60000 (67%)]\tLoss: 142.605645\nTrain Epoch: 18 [50000/60000 (83%)]\tLoss: 130.154141\n====> Epoch: 18 Average loss: 139.5016\n====> Test set loss: 140.3551\nTrain Epoch: 19 [0/60000 (0%)]\tLoss: 142.828760\nTrain Epoch: 19 [10000/60000 (17%)]\tLoss: 148.100400\nTrain Epoch: 19 [20000/60000 (33%)]\tLoss: 139.635000\nTrain Epoch: 19 [30000/60000 (50%)]\tLoss: 143.309307\nTrain Epoch: 19 [40000/60000 (67%)]\tLoss: 133.990312\nTrain Epoch: 19 [50000/60000 (83%)]\tLoss: 139.137617\n====> Epoch: 19 Average loss: 139.2372\n====> Test set loss: 139.9124\nTrain Epoch: 20 [0/60000 (0%)]\tLoss: 146.276963\nTrain Epoch: 20 [10000/60000 (17%)]\tLoss: 134.347959\nTrain Epoch: 20 [20000/60000 (33%)]\tLoss: 138.539922\nTrain Epoch: 20 [30000/60000 (50%)]\tLoss: 149.354434\nTrain Epoch: 20 [40000/60000 (67%)]\tLoss: 140.701621\nTrain Epoch: 20 [50000/60000 (83%)]\tLoss: 127.984102\n====> Epoch: 20 Average loss: 138.8513\n====> Test set loss: 139.4104\nTrain Epoch: 21 [0/60000 (0%)]\tLoss: 145.744746\nTrain Epoch: 21 [10000/60000 (17%)]\tLoss: 144.345557\nTrain Epoch: 21 [20000/60000 (33%)]\tLoss: 138.607979\nTrain Epoch: 21 [30000/60000 (50%)]\tLoss: 136.652051\nTrain Epoch: 21 [40000/60000 (67%)]\tLoss: 131.958340\nTrain Epoch: 21 [50000/60000 (83%)]\tLoss: 133.473975\n====> Epoch: 21 Average loss: 138.8671\n====> Test set loss: 140.2218\nTrain Epoch: 22 [0/60000 (0%)]\tLoss: 141.712031\nTrain Epoch: 22 [10000/60000 (17%)]\tLoss: 136.342275\nTrain Epoch: 22 [20000/60000 (33%)]\tLoss: 134.040049\nTrain Epoch: 22 [30000/60000 (50%)]\tLoss: 142.384980\nTrain Epoch: 22 [40000/60000 (67%)]\tLoss: 138.428877\nTrain Epoch: 22 [50000/60000 (83%)]\tLoss: 135.704277\n====> Epoch: 22 Average loss: 138.4880\n====> Test set loss: 139.7940\nTrain Epoch: 23 [0/60000 (0%)]\tLoss: 139.323154\nTrain Epoch: 23 [10000/60000 (17%)]\tLoss: 132.042480\nTrain Epoch: 23 [20000/60000 (33%)]\tLoss: 134.038037\nTrain Epoch: 23 [30000/60000 (50%)]\tLoss: 140.406934\nTrain Epoch: 23 [40000/60000 (67%)]\tLoss: 144.182148\nTrain Epoch: 23 [50000/60000 (83%)]\tLoss: 132.048994\n====> Epoch: 23 Average loss: 138.4614\n====> Test set loss: 140.5441\nTrain Epoch: 24 [0/60000 (0%)]\tLoss: 140.797803\nTrain Epoch: 24 [10000/60000 (17%)]\tLoss: 136.371133\nTrain Epoch: 24 [20000/60000 (33%)]\tLoss: 136.326562\nTrain Epoch: 24 [30000/60000 (50%)]\tLoss: 138.100195\nTrain Epoch: 24 [40000/60000 (67%)]\tLoss: 145.850469\nTrain Epoch: 24 [50000/60000 (83%)]\tLoss: 129.024873\n====> Epoch: 24 Average loss: 138.6619\n====> Test set loss: 140.1507\nTrain Epoch: 25 [0/60000 (0%)]\tLoss: 128.215176\nTrain Epoch: 25 [10000/60000 (17%)]\tLoss: 149.724189\nTrain Epoch: 25 [20000/60000 (33%)]\tLoss: 138.776895\nTrain Epoch: 25 [30000/60000 (50%)]\tLoss: 132.697969\nTrain Epoch: 25 [40000/60000 (67%)]\tLoss: 148.971533\nTrain Epoch: 25 [50000/60000 (83%)]\tLoss: 138.100762\n====> Epoch: 25 Average loss: 138.4800\n====> Test set loss: 139.0272\nTrain Epoch: 26 [0/60000 (0%)]\tLoss: 133.063779\nTrain Epoch: 26 [10000/60000 (17%)]\tLoss: 144.601963\nTrain Epoch: 26 [20000/60000 (33%)]\tLoss: 137.253467\nTrain Epoch: 26 [30000/60000 (50%)]\tLoss: 137.491289\nTrain Epoch: 26 [40000/60000 (67%)]\tLoss: 142.363770\nTrain Epoch: 26 [50000/60000 (83%)]\tLoss: 147.295322\n====> Epoch: 26 Average loss: 137.8536\n====> Test set loss: 139.0853\nTrain Epoch: 27 [0/60000 (0%)]\tLoss: 138.074912\nTrain Epoch: 27 [10000/60000 (17%)]\tLoss: 140.410850\nTrain Epoch: 27 [20000/60000 (33%)]\tLoss: 135.970293\nTrain Epoch: 27 [30000/60000 (50%)]\tLoss: 139.013066\nTrain Epoch: 27 [40000/60000 (67%)]\tLoss: 141.108574\nTrain Epoch: 27 [50000/60000 (83%)]\tLoss: 136.986348\n====> Epoch: 27 Average loss: 137.8284\n====> Test set loss: 139.0645\nTrain Epoch: 28 [0/60000 (0%)]\tLoss: 137.193594\nTrain Epoch: 28 [10000/60000 (17%)]\tLoss: 137.804668\nTrain Epoch: 28 [20000/60000 (33%)]\tLoss: 137.372695\nTrain Epoch: 28 [30000/60000 (50%)]\tLoss: 141.391455\nTrain Epoch: 28 [40000/60000 (67%)]\tLoss: 132.381777\nTrain Epoch: 28 [50000/60000 (83%)]\tLoss: 131.925000\n====> Epoch: 28 Average loss: 137.4486\n====> Test set loss: 138.7512\nTrain Epoch: 29 [0/60000 (0%)]\tLoss: 134.489639\nTrain Epoch: 29 [10000/60000 (17%)]\tLoss: 144.740449\nTrain Epoch: 29 [20000/60000 (33%)]\tLoss: 137.530605\nTrain Epoch: 29 [30000/60000 (50%)]\tLoss: 138.837187\nTrain Epoch: 29 [40000/60000 (67%)]\tLoss: 135.342695\nTrain Epoch: 29 [50000/60000 (83%)]\tLoss: 141.793477\n====> Epoch: 29 Average loss: 137.2947\n====> Test set loss: 138.1574\nTrain Epoch: 30 [0/60000 (0%)]\tLoss: 132.976113\nTrain Epoch: 30 [10000/60000 (17%)]\tLoss: 129.725918\nTrain Epoch: 30 [20000/60000 (33%)]\tLoss: 139.245635\nTrain Epoch: 30 [30000/60000 (50%)]\tLoss: 139.846543\nTrain Epoch: 30 [40000/60000 (67%)]\tLoss: 132.730488\nTrain Epoch: 30 [50000/60000 (83%)]\tLoss: 132.817891\n====> Epoch: 30 Average loss: 137.8353\n====> Test set loss: 139.0046\nTrain Epoch: 31 [0/60000 (0%)]\tLoss: 135.320000\nTrain Epoch: 31 [10000/60000 (17%)]\tLoss: 143.245996\nTrain Epoch: 31 [20000/60000 (33%)]\tLoss: 141.777314\nTrain Epoch: 31 [30000/60000 (50%)]\tLoss: 138.101660\nTrain Epoch: 31 [40000/60000 (67%)]\tLoss: 142.201270\nTrain Epoch: 31 [50000/60000 (83%)]\tLoss: 137.961475\n====> Epoch: 31 Average loss: 137.5854\n====> Test set loss: 139.0897\nTrain Epoch: 32 [0/60000 (0%)]\tLoss: 143.686807\nTrain Epoch: 32 [10000/60000 (17%)]\tLoss: 132.559102\nTrain Epoch: 32 [20000/60000 (33%)]\tLoss: 142.385293\nTrain Epoch: 32 [30000/60000 (50%)]\tLoss: 138.896201\nTrain Epoch: 32 [40000/60000 (67%)]\tLoss: 136.476084\nTrain Epoch: 32 [50000/60000 (83%)]\tLoss: 147.237871\n====> Epoch: 32 Average loss: 137.5626\n====> Test set loss: 138.5695\nTrain Epoch: 33 [0/60000 (0%)]\tLoss: 139.938984\nTrain Epoch: 33 [10000/60000 (17%)]\tLoss: 126.527002\nTrain Epoch: 33 [20000/60000 (33%)]\tLoss: 128.829854\nTrain Epoch: 33 [30000/60000 (50%)]\tLoss: 141.699062\nTrain Epoch: 33 [40000/60000 (67%)]\tLoss: 135.264854\nTrain Epoch: 33 [50000/60000 (83%)]\tLoss: 141.134531\n====> Epoch: 33 Average loss: 136.9003\n====> Test set loss: 138.8069\nTrain Epoch: 34 [0/60000 (0%)]\tLoss: 140.320605\nTrain Epoch: 34 [10000/60000 (17%)]\tLoss: 138.610352\nTrain Epoch: 34 [20000/60000 (33%)]\tLoss: 140.042510\nTrain Epoch: 34 [30000/60000 (50%)]\tLoss: 128.034766\nTrain Epoch: 34 [40000/60000 (67%)]\tLoss: 141.940859\nTrain Epoch: 34 [50000/60000 (83%)]\tLoss: 132.821289\n====> Epoch: 34 Average loss: 137.2780\n====> Test set loss: 139.0265\nTrain Epoch: 35 [0/60000 (0%)]\tLoss: 135.652432\nTrain Epoch: 35 [10000/60000 (17%)]\tLoss: 130.945420\nTrain Epoch: 35 [20000/60000 (33%)]\tLoss: 137.839590\nTrain Epoch: 35 [30000/60000 (50%)]\tLoss: 134.130225\nTrain Epoch: 35 [40000/60000 (67%)]\tLoss: 132.267754\nTrain Epoch: 35 [50000/60000 (83%)]\tLoss: 138.248828\n====> Epoch: 35 Average loss: 136.9112\n====> Test set loss: 139.1857\nTrain Epoch: 36 [0/60000 (0%)]\tLoss: 135.209629\nTrain Epoch: 36 [10000/60000 (17%)]\tLoss: 134.561396\nTrain Epoch: 36 [20000/60000 (33%)]\tLoss: 128.625625\nTrain Epoch: 36 [30000/60000 (50%)]\tLoss: 138.611787\nTrain Epoch: 36 [40000/60000 (67%)]\tLoss: 132.785908\nTrain Epoch: 36 [50000/60000 (83%)]\tLoss: 135.739326\n====> Epoch: 36 Average loss: 136.7691\n====> Test set loss: 138.5626\nTrain Epoch: 37 [0/60000 (0%)]\tLoss: 134.755127\nTrain Epoch: 37 [10000/60000 (17%)]\tLoss: 137.043271\nTrain Epoch: 37 [20000/60000 (33%)]\tLoss: 135.281738\nTrain Epoch: 37 [30000/60000 (50%)]\tLoss: 131.796445\nTrain Epoch: 37 [40000/60000 (67%)]\tLoss: 134.802598\nTrain Epoch: 37 [50000/60000 (83%)]\tLoss: 133.306230\n====> Epoch: 37 Average loss: 136.9367\n====> Test set loss: 138.6250\nTrain Epoch: 38 [0/60000 (0%)]\tLoss: 132.876016\nTrain Epoch: 38 [10000/60000 (17%)]\tLoss: 136.163379\nTrain Epoch: 38 [20000/60000 (33%)]\tLoss: 144.036816\nTrain Epoch: 38 [30000/60000 (50%)]\tLoss: 140.935469\nTrain Epoch: 38 [40000/60000 (67%)]\tLoss: 137.296621\nTrain Epoch: 38 [50000/60000 (83%)]\tLoss: 139.898633\n====> Epoch: 38 Average loss: 137.1201\n====> Test set loss: 138.3185\nTrain Epoch: 39 [0/60000 (0%)]\tLoss: 138.019824\nTrain Epoch: 39 [10000/60000 (17%)]\tLoss: 138.720957\nTrain Epoch: 39 [20000/60000 (33%)]\tLoss: 126.584414\nTrain Epoch: 39 [30000/60000 (50%)]\tLoss: 142.893262\nTrain Epoch: 39 [40000/60000 (67%)]\tLoss: 139.405488\nTrain Epoch: 39 [50000/60000 (83%)]\tLoss: 136.636113\n====> Epoch: 39 Average loss: 136.3871\n====> Test set loss: 138.3985\nTrain Epoch: 40 [0/60000 (0%)]\tLoss: 135.694414\nTrain Epoch: 40 [10000/60000 (17%)]\tLoss: 133.277510\nTrain Epoch: 40 [20000/60000 (33%)]\tLoss: 141.497285\nTrain Epoch: 40 [30000/60000 (50%)]\tLoss: 143.773428\nTrain Epoch: 40 [40000/60000 (67%)]\tLoss: 138.908818\nTrain Epoch: 40 [50000/60000 (83%)]\tLoss: 137.238887\n====> Epoch: 40 Average loss: 136.4849\n====> Test set loss: 138.7309\nTrain Epoch: 41 [0/60000 (0%)]\tLoss: 131.266416\nTrain Epoch: 41 [10000/60000 (17%)]\tLoss: 128.950498\nTrain Epoch: 41 [20000/60000 (33%)]\tLoss: 135.949395\nTrain Epoch: 41 [30000/60000 (50%)]\tLoss: 131.223418\nTrain Epoch: 41 [40000/60000 (67%)]\tLoss: 139.199814\nTrain Epoch: 41 [50000/60000 (83%)]\tLoss: 135.652207\n====> Epoch: 41 Average loss: 136.3152\n====> Test set loss: 138.2695\nTrain Epoch: 42 [0/60000 (0%)]\tLoss: 136.766084\nTrain Epoch: 42 [10000/60000 (17%)]\tLoss: 129.649629\nTrain Epoch: 42 [20000/60000 (33%)]\tLoss: 139.497949\nTrain Epoch: 42 [30000/60000 (50%)]\tLoss: 139.142949\nTrain Epoch: 42 [40000/60000 (67%)]\tLoss: 136.426777\nTrain Epoch: 42 [50000/60000 (83%)]\tLoss: 145.578711\n====> Epoch: 42 Average loss: 136.2979\n====> Test set loss: 138.1028\nTrain Epoch: 43 [0/60000 (0%)]\tLoss: 135.628525\nTrain Epoch: 43 [10000/60000 (17%)]\tLoss: 139.608018\nTrain Epoch: 43 [20000/60000 (33%)]\tLoss: 127.002520\nTrain Epoch: 43 [30000/60000 (50%)]\tLoss: 131.130547\nTrain Epoch: 43 [40000/60000 (67%)]\tLoss: 140.523877\nTrain Epoch: 43 [50000/60000 (83%)]\tLoss: 130.519336\n====> Epoch: 43 Average loss: 136.2624\n====> Test set loss: 138.4621\nTrain Epoch: 44 [0/60000 (0%)]\tLoss: 133.419424\nTrain Epoch: 44 [10000/60000 (17%)]\tLoss: 134.585781\nTrain Epoch: 44 [20000/60000 (33%)]\tLoss: 134.144746\nTrain Epoch: 44 [30000/60000 (50%)]\tLoss: 133.121133\nTrain Epoch: 44 [40000/60000 (67%)]\tLoss: 138.058896\nTrain Epoch: 44 [50000/60000 (83%)]\tLoss: 131.938066\n====> Epoch: 44 Average loss: 136.1050\n====> Test set loss: 138.3132\nTrain Epoch: 45 [0/60000 (0%)]\tLoss: 140.941387\nTrain Epoch: 45 [10000/60000 (17%)]\tLoss: 140.248877\nTrain Epoch: 45 [20000/60000 (33%)]\tLoss: 131.534854\nTrain Epoch: 45 [30000/60000 (50%)]\tLoss: 131.296895\nTrain Epoch: 45 [40000/60000 (67%)]\tLoss: 135.940625\nTrain Epoch: 45 [50000/60000 (83%)]\tLoss: 137.045098\n====> Epoch: 45 Average loss: 135.8966\n====> Test set loss: 138.1559\nTrain Epoch: 46 [0/60000 (0%)]\tLoss: 134.558662\nTrain Epoch: 46 [10000/60000 (17%)]\tLoss: 137.341201\nTrain Epoch: 46 [20000/60000 (33%)]\tLoss: 142.657578\nTrain Epoch: 46 [30000/60000 (50%)]\tLoss: 141.404580\nTrain Epoch: 46 [40000/60000 (67%)]\tLoss: 141.554453\nTrain Epoch: 46 [50000/60000 (83%)]\tLoss: 137.059424\n====> Epoch: 46 Average loss: 135.7473\n====> Test set loss: 138.0879\nTrain Epoch: 47 [0/60000 (0%)]\tLoss: 133.844746\nTrain Epoch: 47 [10000/60000 (17%)]\tLoss: 136.885332\nTrain Epoch: 47 [20000/60000 (33%)]\tLoss: 139.014697\nTrain Epoch: 47 [30000/60000 (50%)]\tLoss: 141.997705\nTrain Epoch: 47 [40000/60000 (67%)]\tLoss: 135.521787\nTrain Epoch: 47 [50000/60000 (83%)]\tLoss: 138.490371\n====> Epoch: 47 Average loss: 135.6797\n====> Test set loss: 138.3150\nTrain Epoch: 48 [0/60000 (0%)]\tLoss: 132.441084\nTrain Epoch: 48 [10000/60000 (17%)]\tLoss: 129.993223\nTrain Epoch: 48 [20000/60000 (33%)]\tLoss: 139.223389\nTrain Epoch: 48 [30000/60000 (50%)]\tLoss: 130.697764\nTrain Epoch: 48 [40000/60000 (67%)]\tLoss: 129.672070\nTrain Epoch: 48 [50000/60000 (83%)]\tLoss: 134.514570\n====> Epoch: 48 Average loss: 135.8091\n====> Test set loss: 138.5184\nTrain Epoch: 49 [0/60000 (0%)]\tLoss: 134.366455\nTrain Epoch: 49 [10000/60000 (17%)]\tLoss: 133.107773\nTrain Epoch: 49 [20000/60000 (33%)]\tLoss: 135.585283\nTrain Epoch: 49 [30000/60000 (50%)]\tLoss: 140.623311\nTrain Epoch: 49 [40000/60000 (67%)]\tLoss: 123.857402\nTrain Epoch: 49 [50000/60000 (83%)]\tLoss: 133.619316\n====> Epoch: 49 Average loss: 135.7575\n====> Test set loss: 137.6244\nTrain Epoch: 50 [0/60000 (0%)]\tLoss: 127.794609\nTrain Epoch: 50 [10000/60000 (17%)]\tLoss: 140.842588\nTrain Epoch: 50 [20000/60000 (33%)]\tLoss: 138.272607\nTrain Epoch: 50 [30000/60000 (50%)]\tLoss: 140.344805\nTrain Epoch: 50 [40000/60000 (67%)]\tLoss: 129.388584\nTrain Epoch: 50 [50000/60000 (83%)]\tLoss: 131.476367\n====> Epoch: 50 Average loss: 135.6128\n====> Test set loss: 138.1297\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n#os.mkdir('./samples')\nwith torch.no_grad():\n    z = torch.randn(64, 2).cuda()\n    sample = vae.decoder(z).cuda()\n    sample.view(64,1,28,28)\n    \n    save_image(sample.view(64, 1, 28, 28), './samples/sample_' + '.png')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T06:51:59.345872Z","iopub.execute_input":"2023-04-19T06:51:59.346291Z","iopub.status.idle":"2023-04-19T06:51:59.367783Z","shell.execute_reply.started":"2023-04-19T06:51:59.346254Z","shell.execute_reply":"2023-04-19T06:51:59.366742Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\n\n!tar -czf samples.tar.gz samples\n\nfrom IPython.display import FileLink\n\nFileLink(r'samples.tar.gz')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T07:01:43.722894Z","iopub.execute_input":"2023-04-19T07:01:43.724133Z","iopub.status.idle":"2023-04-19T07:01:44.964358Z","shell.execute_reply.started":"2023-04-19T07:01:43.724065Z","shell.execute_reply":"2023-04-19T07:01:44.963062Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/samples.tar.gz","text/html":"<a href='samples.tar.gz' target='_blank'>samples.tar.gz</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(vae, './samples/vae.pt')","metadata":{"execution":{"iopub.status.busy":"2023-04-19T07:01:27.910473Z","iopub.execute_input":"2023-04-19T07:01:27.910855Z","iopub.status.idle":"2023-04-19T07:01:27.930241Z","shell.execute_reply.started":"2023-04-19T07:01:27.910822Z","shell.execute_reply":"2023-04-19T07:01:27.928797Z"},"trusted":true},"execution_count":18,"outputs":[]}]}